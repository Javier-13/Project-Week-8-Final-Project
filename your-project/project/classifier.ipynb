{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPEECH ANALYSER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't be commenting that much this final program as it is the merge of the previous ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "import speech_recognition as sr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Recognizer and\n",
    "r = sr.Recognizer()\n",
    "audios = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "review1 = sr.AudioFile('../data/OUATIH1.wav')\n",
    "with review1 as source:\n",
    "    audios.append(r.record(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "review2 = sr.AudioFile('../data/OUATIH2.wav')\n",
    "with review2 as source:\n",
    "    audios.append(r.record(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "review3 = sr.AudioFile('../data/OUATIH3.wav')\n",
    "with review3 as source:\n",
    "    audios.append(r.record(source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening and cleaning the data por nlp previously used\n",
    "\n",
    "with open('../data/movie_data/full_train.txt', 'r', encoding = \"utf8\") as train_file:\n",
    "    reviews_train = [review.strip() for review in train_file]\n",
    "\n",
    "def cleaning(par):\n",
    "    \n",
    "    '''Function to remove punctuation\n",
    "    from the given paragraph and html \n",
    "    expressions that are not needed'''\n",
    "    \n",
    "    html = re.compile(\"(<br\\s*/><br\\s*/>)|(\\-)|(\\/)\")\n",
    "    \n",
    "    final = [s.translate(str.maketrans('', '', string.punctuation)).lower() for s in par]\n",
    "    final_par = [html.sub(\" \", line) for line in final]\n",
    "    return final\n",
    "\n",
    "clean_review_train = cleaning(reviews_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34662\\Anaconda3\\envs\\Python\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the model\n",
    "\n",
    "TfidVect = TfidfVectorizer()\n",
    "tfv_review_train_matrix = TfidVect.fit_transform(clean_review_train)\n",
    "\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_tr_train, X_tr_test, y_tr_train, y_tr_test = \\\n",
    "    train_test_split(tfv_review_train_matrix, target, train_size = 0.75)\n",
    "\n",
    "final_model = LogisticRegression(C=1)\n",
    "final_model.fit(tfv_review_train_matrix, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We send each review to the google API and get the value as a string\n",
    "#So we can categorize them as positive or negative\n",
    "\n",
    "trials = [r.recognize_google(audios[i]) for i in range(3)]\n",
    "trial_prediction = TfidVect.transform(trials)\n",
    "final_model.predict(trial_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
